{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk inserting segment Ids\n",
    "This notebook handles the translation of latitude/longitude columns within a dataset to their nearest segment ID. This is a very compute-intensive operation which should only need to be run one time on any given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from zipfile import ZipFile as zzip\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "LION_ZIP_DIR = \"input_data/nyclion_19b.zip\"\n",
    "GDB_FILE = r\"input_data/lion/lion.gdb\"\n",
    "OUTPUT_DIR = \"output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download LION data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and store lion files\n",
    "url = r\"https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyclion_19b.zip\"\n",
    "\n",
    "# download the file contents in binary format\n",
    "r = requests.get(url)\n",
    "# open method to open a file on your system and write the contents\n",
    "with open(LION_ZIP_DIR, \"wb\") as file:\n",
    "    file.write(r.content)\n",
    "\n",
    "# opening the zip file in READ mode\n",
    "with zzip(LION_ZIP_DIR, 'r') as file:\n",
    "    # printing all the contents of the zip file\n",
    "    file.printdir()\n",
    "\n",
    "    # extracting all the files\n",
    "    file.extractall(\"input_data/\")\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['node', 'node_stname', 'altnames', 'lion']\n"
     ]
    }
   ],
   "source": [
    "layers = fiona.listlayers(GDB_FILE)\n",
    "print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lion_gdf = gpd.read_file(GDB_FILE, engine='pyogrio', layer='lion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  226977\n",
      "After:  32966\n"
     ]
    }
   ],
   "source": [
    "# Remove rows outside of manhattan just to clean up and speed up operations\n",
    "print(\"Before: \", len(lion_gdf.index))\n",
    "lion_gdf = lion_gdf[lion_gdf.LBoro == 1]\n",
    "print(\"After: \", len(lion_gdf.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_id_from_coords(lat, lng):\n",
    "    point = Point(lng, lat)\n",
    "    if lion_gdf.crs.is_geographic:\n",
    "        point_gdf = gpd.GeoDataFrame([{'geometry': point}], crs=lion_gdf.crs)\n",
    "    else:\n",
    "        point_gdf = gpd.GeoDataFrame([{'geometry': point}], crs=\"EPSG:4326\").to_crs(lion_gdf.crs)\n",
    "    \n",
    "    lion_gdf['distance'] = lion_gdf.geometry.distance(point_gdf.iloc[0].geometry)\n",
    "    nearest_segment = lion_gdf.loc[lion_gdf['distance'].idxmin()]\n",
    "    segment_id = nearest_segment['SegmentID']\n",
    "    return segment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0297696'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick test\n",
    "get_segment_id_from_coords(40.748433, -73.985656)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segment_ids():\n",
    "    new_segment_ids = {}\n",
    "    # Opening JSON file\n",
    "    f = open(f\"{OUTPUT_DIR}/segment_id_dict.json\")\n",
    "    data = json.load(f)\n",
    "    for key in data.keys():\n",
    "        coordinates_tuple = tuple(map(float, key.split(',')))\n",
    "        new_segment_ids[coordinates_tuple] = data[key]\n",
    "\n",
    "    return new_segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_ids = load_segment_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_segment_id_column(df):\n",
    "    global segment_ids\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            lat = row['Latitude']\n",
    "            lng = row['Longitude']\n",
    "            if (lat, lng) not in segment_ids.keys():\n",
    "                print(f'Getting segment for ({lat}, {lng})')\n",
    "                segment_id = get_segment_id_from_coords(lat, lng)\n",
    "                matching_rows = df[(df.Latitude == lat) & (df.Longitude == lng)]\n",
    "                print(f'Updating: {len(matching_rows)}')\n",
    "                df.loc[(df.Latitude == lat) & (df.Longitude == lng), 'SegmentId'] = segment_id\n",
    "                \n",
    "                print(f'Updating: {len(matching_rows)}')\n",
    "                segment_ids[(lat, lng)] = segment_id\n",
    "\n",
    "                rows_left = df['SegmentId'].isnull().sum()\n",
    "                print(f'Rows left: {rows_left}')\n",
    "        except:\n",
    "            print(f\"Unable to translate ({lat}, {lng}), skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBWAY_DATA = \"input_data/MTA_Subway_Hourly_Ridership_20240607.csv\"\n",
    "BIKE_DATA_1 = \"input_data/202401-citibike-tripdata_1.csv\"\n",
    "BIKE_DATA_2 = \"input_data/202401-citibike-tripdata_2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transit = pd.read_csv(SUBWAY_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1987659 entries, 0 to 1987658\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Dtype  \n",
      "---  ------                    -----  \n",
      " 0   transit_timestamp         object \n",
      " 1   transit_mode              object \n",
      " 2   station_complex_id        object \n",
      " 3   station_complex           object \n",
      " 4   borough                   object \n",
      " 5   payment_method            object \n",
      " 6   fare_class_category       object \n",
      " 7   ridership                 int64  \n",
      " 8   transfers                 int64  \n",
      " 9   Latitude                  float64\n",
      " 10  Longitude                 float64\n",
      " 11  Georeference              object \n",
      " 12  Counties                  int64  \n",
      " 13  NYS Municipal Boundaries  int64  \n",
      " 14  New York Zip Codes        float64\n",
      " 15  SegmentId                 object \n",
      "dtypes: float64(3), int64(4), object(9)\n",
      "memory usage: 257.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_transit.columns\n",
    "df_transit = df_transit[df_transit.borough == 'Manhattan']\n",
    "df_transit.rename(columns={'latitude': 'Latitude', 'longitude': 'Longitude'}, inplace=True)\n",
    "df_transit['SegmentId'] = None\n",
    "\n",
    "df_transit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected length of segment ids:  161\n",
      "Actual:  161\n"
     ]
    }
   ],
   "source": [
    "uniq = df_transit.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "print(\"Expected length of segment ids: \", len(uniq))\n",
    "print(\"Actual: \", len(segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madd_segment_id_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transit\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m, in \u001b[0;36madd_segment_id_column\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_segment_id_column\u001b[39m(df):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m segment_ids\n\u001b[0;32m----> 3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLatitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlng\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLongitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/git/accessibility-app/.venv/lib/python3.11/site-packages/pandas/core/frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1552\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1554\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1556\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/git/accessibility-app/.venv/lib/python3.11/site-packages/pandas/core/series.py:588\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    586\u001b[0m manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 588\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mSingleBlockManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    590\u001b[0m     data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n",
      "File \u001b[0;32m~/Documents/git/accessibility-app/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1863\u001b[0m, in \u001b[0;36mSingleBlockManager.from_array\u001b[0;34m(cls, array, index, refs)\u001b[0m\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(blocks[\u001b[38;5;241m0\u001b[39m], axes[\u001b[38;5;241m0\u001b[39m], verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1863\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_array\u001b[39m(\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;28mcls\u001b[39m, array: ArrayLike, index: Index, refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleBlockManager:\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;124;03m    Constructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m     array \u001b[38;5;241m=\u001b[39m maybe_coerce_values(array)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "add_segment_id_column(df_transit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum start date: 2024-01-01 00:00:00\n",
      "Maximum start date: 2024-03-31 23:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/s9j0wvg542n0d4_0n5lwnp140000gn/T/ipykernel_91745/820701446.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_transit['transit_timestamp'] = pd.to_datetime(df_transit['transit_timestamp'])\n"
     ]
    }
   ],
   "source": [
    "df_transit['transit_timestamp'] = pd.to_datetime(df_transit['transit_timestamp'])\n",
    "min_start_date = df_transit['transit_timestamp'].min()\n",
    "max_start_date = df_transit['transit_timestamp'].max()\n",
    "\n",
    "print(f\"Minimum start date: {min_start_date}\")\n",
    "print(f\"Maximum start date: {max_start_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add column to bike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike_1 = pd.read_csv(BIKE_DATA_1, dtype={\"start_station_id\": str})\n",
    "df_bike_2 = pd.read_csv(BIKE_DATA_2, dtype={\"start_station_id\": str, \"end_station_id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike = pd.concat([df_bike_1, df_bike_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1954376 entries, 0 to 1954375\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   ride_id             object \n",
      " 1   rideable_type       object \n",
      " 2   started_at          object \n",
      " 3   ended_at            object \n",
      " 4   start_station_name  object \n",
      " 5   start_station_id    object \n",
      " 6   end_station_name    object \n",
      " 7   end_station_id      object \n",
      " 8   start_lat           float64\n",
      " 9   start_lng           float64\n",
      " 10  end_lat             float64\n",
      " 11  end_lng             float64\n",
      " 12  member_casual       object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 193.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_bike.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum start date: 2024-01-01 00:00:03\n",
      "Maximum start date: 2024-01-31 23:59:59\n"
     ]
    }
   ],
   "source": [
    "df_bike['started_at'] = pd.to_datetime(df_bike['started_at'])\n",
    "min_start_date = df_bike['started_at'].min()\n",
    "max_start_date = df_bike['started_at'].max()\n",
    "\n",
    "print(f\"Minimum start date: {min_start_date}\")\n",
    "print(f\"Maximum start date: {max_start_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bike_new = pd.DataFrame()\n",
    "df_bike['started_at'] = pd.to_datetime(df_bike['started_at'])\n",
    "df_bike['ended_at'] = pd.to_datetime(df_bike['ended_at'])\n",
    "\n",
    "df_bike_new['Timestamp'] = pd.concat([df_bike['started_at'], df_bike['ended_at']], ignore_index=True)\n",
    "df_bike_new['Timestamp'] = pd.to_datetime(df_bike_new['Timestamp'])\n",
    "df_bike_new['Timestamp_Rounded'] = df_bike_new['Timestamp'].dt.round(\"h\")\n",
    "df_bike_new['Latitude'] = pd.concat([df_bike['start_lat'], df_bike['end_lat']], ignore_index=True)\n",
    "df_bike_new['Longitude'] = pd.concat([df_bike['start_lng'], df_bike['end_lng']], ignore_index=True)\n",
    "\n",
    "# Round the lat/lngs\n",
    "df_bike_new['Latitude'] = df_bike_new['Latitude'].round(3)\n",
    "df_bike_new['Longitude'] = df_bike_new['Longitude'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique lat/long:  6475\n",
      "Unique lat/long/time:  926827\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique lat/long: \", len(df_bike_new.drop_duplicates(subset=['Latitude', 'Longitude'])))\n",
    "print(\"Unique lat/long/time: \", len(df_bike_new.drop_duplicates(subset=['Latitude', 'Longitude', 'Timestamp_Rounded'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected length of segment ids:  6636\n",
      "Actual:  161\n"
     ]
    }
   ],
   "source": [
    "uniq = df_bike_new.drop_duplicates(subset=['Latitude', 'Longitude'])\n",
    "print(\"Expected length of segment ids: \", len(segment_ids) + len(uniq))\n",
    "print(\"Actual: \", len(segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke up bike into 39088 chunks\n"
     ]
    }
   ],
   "source": [
    "# Split up DF into chunks to be pooled\n",
    "chunk_size = 100\n",
    "num_chunks = len(df_bike_new) // chunk_size + (len(df_bike_new) % chunk_size > 0)\n",
    "chunks = [df_bike_new.iloc[i * chunk_size:(i + 1) * chunk_size] for i in range(num_chunks)]\n",
    "print(f\"Broke up bike into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_segment_id_column(df_bike_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of segment ids:  6635\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Timestamp_Rounded</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>SegmentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-25 20:39:09</td>\n",
       "      <td>2024-01-25 21:00:00</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.991</td>\n",
       "      <td>0032805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-15 18:44:36</td>\n",
       "      <td>2024-01-15 19:00:00</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.988</td>\n",
       "      <td>0032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03 19:27:58</td>\n",
       "      <td>2024-01-03 19:00:00</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.988</td>\n",
       "      <td>0032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-22 18:29:46</td>\n",
       "      <td>2024-01-22 18:00:00</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.988</td>\n",
       "      <td>0032949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-27 09:55:39</td>\n",
       "      <td>2024-01-27 10:00:00</td>\n",
       "      <td>40.735</td>\n",
       "      <td>-73.988</td>\n",
       "      <td>0032949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp   Timestamp_Rounded  Latitude  Longitude SegmentId\n",
       "0 2024-01-25 20:39:09 2024-01-25 21:00:00    40.735    -73.991   0032805\n",
       "1 2024-01-15 18:44:36 2024-01-15 19:00:00    40.735    -73.988   0032949\n",
       "2 2024-01-03 19:27:58 2024-01-03 19:00:00    40.735    -73.988   0032949\n",
       "3 2024-01-22 18:29:46 2024-01-22 18:00:00    40.735    -73.988   0032949\n",
       "4 2024-01-27 09:55:39 2024-01-27 10:00:00    40.735    -73.988   0032949"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Length of segment ids: \", len(segment_ids))\n",
    "df_bike_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment ids saved\n"
     ]
    }
   ],
   "source": [
    "# Convert segment ids into json format\n",
    "segment_ids_as_json = {}\n",
    "for key in segment_ids.keys():\n",
    "    tuple_str = \",\".join([str(key[0]), str(key[1])])\n",
    "    segment_ids_as_json[tuple_str] = segment_ids[key]\n",
    "\n",
    "# Save segment ids for future use\n",
    "with open(f\"{OUTPUT_DIR}/segment_id_dict.json\", \"w\") as outfile: \n",
    "    json.dump(segment_ids_as_json, outfile)\n",
    "    print(\"Segment ids saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bike data saved: output//202401-citibike-tripdata_with_segments.csv\n",
      "Transit data saved: output//MTA_Subway_Hourly_Ridership_20240607_with_segments.csv\n"
     ]
    }
   ],
   "source": [
    "# Save our dataframes\n",
    "SUBWAY_DATA = \"input_data/MTA_Subway_Hourly_Ridership_20240607.csv\"\n",
    "BIKE_DATA_1 = \"input_data/202401-citibike-tripdata_1.csv\"\n",
    "BIKE_DATA_2 = \"input_data/202401-citibike-tripdata_2.csv\"\n",
    "\n",
    "bike_csv = f\"{OUTPUT_DIR}/202401-citibike-tripdata_with_segments.csv\"\n",
    "df_bike_new.to_csv(bike_csv, index=False)\n",
    "print(f\"Bike data saved: {bike_csv}\")\n",
    "\n",
    "transit_csv = f\"{OUTPUT_DIR}/MTA_Subway_Hourly_Ridership_20240607_with_segments.csv\"\n",
    "df_transit.to_csv(transit_csv, index=False)\n",
    "print(f\"Transit data saved: {transit_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp30830",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
